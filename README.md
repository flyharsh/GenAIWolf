# ğŸº GenAIwolf

GenAIwolf is a modular, scalable, and cost-efficient Retrieval-Augmented Generation (RAG) application. It enables users to ingest documents (PDF, DOCX, TXT), embed them using HuggingFace embeddings, store them in a Qdrant vector store, and retrieve context-based answers powered by OpenAI GPT-3.5 Turbo, optimizing LLM usage through caching and dynamic retrieval sizing.

---

## ğŸš€ Features

- **Document Ingestion**
  - PDF, DOCX, TXT file support
  - Smart chunking with overlapping texts
  - UUID-based chunk identification

- **Embedding & Vector Storage**
  - HuggingFace Embeddings (`sentence-transformers/all-MiniLM-L6-v2`)
  - Cloud-hosted Qdrant vector store integration

- **Retrieval & QA**
  - Dynamic context retrieval based on query complexity
  - Retrieval-QA chaining for grounded responses

- **Cost Optimization**
  - Redis-based caching for minimizing redundant OpenAI calls
  - Dynamic retrieval sizes to reduce unnecessary tokens usage

- **Containerization & Development**
  - Docker & Docker Compose for rapid development and deployment
  - Adheres to the Twelve-Factor App methodology (config via `.env`)

---

## ğŸ“ Project Structure

```text
GenAIwolf/
â”œâ”€â”€ .env                      # Environment variables and secrets
â”œâ”€â”€ config.py                 # Loads configuration from `.env`
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ Dockerfile.backend        # Backend Dockerfile (FastAPI)
â”œâ”€â”€ Dockerfile.ui             # Frontend Dockerfile (Streamlit)
â”œâ”€â”€ docker-compose.yml        # Docker Compose for service orchestration
â”œâ”€â”€ data/                     
â”‚   â””â”€â”€ raw/                  # Raw documents (PDF/DOCX/TXT)
â””â”€â”€ src/                      
    â”œâ”€â”€ api/                  # FastAPI backend
    â”‚   â”œâ”€â”€ app.py            # Entry-point for FastAPI
    â”‚   â””â”€â”€ routers/          # Additional FastAPI routers
    â”œâ”€â”€ core/                 
    â”‚   â””â”€â”€ interfaces.py     # Abstract base classes/interfaces
    â”œâ”€â”€ ingest/               
    â”‚   â””â”€â”€ pdf_ingestor.py   # Document ingestion logic
    â”œâ”€â”€ embed/                
    â”‚   â””â”€â”€ hf_embedder.py    # Embedding logic using HuggingFace
    â”œâ”€â”€ store/                
    â”‚   â””â”€â”€ qdrant_store.py   # Qdrant storage adapter
    â”œâ”€â”€ retrieve/             
    â”‚   â”œâ”€â”€ retriever.py      # Retriever implementation
    â”‚   â””â”€â”€ strategies.py     # Retrieval strategy implementation
    â”œâ”€â”€ llm/                  
    â”‚   â””â”€â”€ openai_llm.py     # OpenAI API client wrapper
    â””â”€â”€ chain/                
        â””â”€â”€ retrieval_qa.py   # Retrieval-QA chaining logic
